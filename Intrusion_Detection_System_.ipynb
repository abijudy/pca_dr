{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import accuracy_score\n"
      ],
      "metadata": {
        "id": "nlSQD7aLwG2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "dataset = pd.read_csv('1.csv')\n",
        "dataset.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "8eX3VJA-wLaJ",
        "outputId": "a7f019be-6c9c-4170-8226-6d58f341ed08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Dir        Flgs     SrcAddr     DstAddr  Sport  Dport  SrcBytes  \\\n",
              "0     ->   e          10.0.1.172  10.0.1.150  58059   1111       496   \n",
              "1     ->   e          10.0.1.172  10.0.1.150  58062   1111       496   \n",
              "2     ->   e          10.0.1.172  10.0.1.150  58065   1111       496   \n",
              "3     ->   e          10.0.1.172  10.0.1.150  58067   1111       496   \n",
              "4     ->   e          10.0.1.172  10.0.1.150  58069   1111       496   \n",
              "\n",
              "   DstBytes   SrcLoad  DstLoad  ...  Packet_num  Temp  SpO2  Pulse_Rate  SYS  \\\n",
              "0       186  276914.0  92305.0  ...         1.0  28.9   0.0         0.0  0.0   \n",
              "1       186  230984.0  76995.0  ...         2.0  28.9   0.0         0.0  0.0   \n",
              "2       186  218470.0  72823.0  ...         3.0  28.9  89.0       104.0  0.0   \n",
              "3       186  203376.0  67792.0  ...         4.0  28.9  89.0       104.0  0.0   \n",
              "4       186  235723.0  78574.0  ...         5.0  28.9  89.0       101.0  0.0   \n",
              "\n",
              "   DIA  Heart_rate  Resp_Rate   ST  Label  \n",
              "0  0.0         0.0        0.0  0.0    0.0  \n",
              "1  0.0        78.0       17.0  0.4    0.0  \n",
              "2  0.0        78.0       17.0  0.4    0.0  \n",
              "3  0.0        79.0       17.0  0.4    0.0  \n",
              "4  0.0        79.0       17.0  0.4    0.0  \n",
              "\n",
              "[5 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fcd1fa93-9555-43e8-b856-24cac27060eb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dir</th>\n",
              "      <th>Flgs</th>\n",
              "      <th>SrcAddr</th>\n",
              "      <th>DstAddr</th>\n",
              "      <th>Sport</th>\n",
              "      <th>Dport</th>\n",
              "      <th>SrcBytes</th>\n",
              "      <th>DstBytes</th>\n",
              "      <th>SrcLoad</th>\n",
              "      <th>DstLoad</th>\n",
              "      <th>...</th>\n",
              "      <th>Packet_num</th>\n",
              "      <th>Temp</th>\n",
              "      <th>SpO2</th>\n",
              "      <th>Pulse_Rate</th>\n",
              "      <th>SYS</th>\n",
              "      <th>DIA</th>\n",
              "      <th>Heart_rate</th>\n",
              "      <th>Resp_Rate</th>\n",
              "      <th>ST</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-&gt;</td>\n",
              "      <td>e</td>\n",
              "      <td>10.0.1.172</td>\n",
              "      <td>10.0.1.150</td>\n",
              "      <td>58059</td>\n",
              "      <td>1111</td>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>276914.0</td>\n",
              "      <td>92305.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-&gt;</td>\n",
              "      <td>e</td>\n",
              "      <td>10.0.1.172</td>\n",
              "      <td>10.0.1.150</td>\n",
              "      <td>58062</td>\n",
              "      <td>1111</td>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>230984.0</td>\n",
              "      <td>76995.0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-&gt;</td>\n",
              "      <td>e</td>\n",
              "      <td>10.0.1.172</td>\n",
              "      <td>10.0.1.150</td>\n",
              "      <td>58065</td>\n",
              "      <td>1111</td>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>218470.0</td>\n",
              "      <td>72823.0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-&gt;</td>\n",
              "      <td>e</td>\n",
              "      <td>10.0.1.172</td>\n",
              "      <td>10.0.1.150</td>\n",
              "      <td>58067</td>\n",
              "      <td>1111</td>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>203376.0</td>\n",
              "      <td>67792.0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-&gt;</td>\n",
              "      <td>e</td>\n",
              "      <td>10.0.1.172</td>\n",
              "      <td>10.0.1.150</td>\n",
              "      <td>58069</td>\n",
              "      <td>1111</td>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>235723.0</td>\n",
              "      <td>78574.0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 44 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fcd1fa93-9555-43e8-b856-24cac27060eb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fcd1fa93-9555-43e8-b856-24cac27060eb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fcd1fa93-9555-43e8-b856-24cac27060eb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HWCGESdwHhEG",
        "outputId": "5d97f8d1-0ee0-4dd4-9e80-b07bc9bda8fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16318, 44)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing data\n",
        "# Label Encoding\n",
        "#le = LabelEncoder()\n",
        "#dataset['target'] = le.fit_transform(dataset['target'])"
      ],
      "metadata": {
        "id": "zNAOVFpOwQdA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = dataset.drop('Dir', axis=1,inplace=True)\n",
        "x1 = dataset.drop('SrcAddr', axis=1,inplace=True)\n",
        "x1 = dataset.drop('DstAddr', axis=1,inplace=True)\n",
        "x1 = dataset.drop('Sport', axis=1,inplace=True)\n",
        "x1 = dataset.drop('Dport', axis=1,inplace=True)\n",
        "x1 = dataset.drop('SrcMac', axis=1,inplace=True)\n",
        "x1 = dataset.drop('DstMac', axis=1,inplace=True)\n",
        "df= dataset.drop('Flgs', axis=1)\n",
        "#df=dataset.drop('Sport',axis=1)\n",
        "print (df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP0aMz6KyejI",
        "outputId": "37278c9b-fbc3-4bf9-9b3a-3f63cd7f1e58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       SrcBytes  DstBytes   SrcLoad  DstLoad  SrcGap  DstGap     SIntPkt  \\\n",
            "0           496       186  276914.0  92305.0       0       0    3.582333   \n",
            "1           496       186  230984.0  76995.0       0       0    4.294667   \n",
            "2           496       186  218470.0  72823.0       0       0    4.540667   \n",
            "3           496       186  203376.0  67792.0       0       0    4.877667   \n",
            "4           496       186  235723.0  78574.0       0       0    4.208333   \n",
            "...         ...       ...       ...      ...     ...     ...         ...   \n",
            "13427       496       186  257529.0  85843.0       0       0    3.852000   \n",
            "13428       496       186  266954.0  88985.0       0       0    3.716000   \n",
            "13429       496       186  226071.0  75357.0       0       0    4.388000   \n",
            "13430       496       186  284024.0  94675.0       0       0    3.492667   \n",
            "13431       496       186    9389.0   3130.0       0       0  105.659336   \n",
            "\n",
            "        DIntPkt  SIntPktAct  DIntPktAct  ...  Packet_num  Temp  SpO2  \\\n",
            "0        1.9015         0.0           0  ...         1.0  28.9   0.0   \n",
            "1        2.9015         0.0           0  ...         2.0  28.9   0.0   \n",
            "2        3.2945         0.0           0  ...         3.0  28.9  89.0   \n",
            "3        3.3320         0.0           0  ...         4.0  28.9  89.0   \n",
            "4        2.8635         0.0           0  ...         5.0  28.9  89.0   \n",
            "...         ...         ...         ...  ...         ...   ...   ...   \n",
            "13427    2.3345         0.0           0  ...     13424.0  26.7  98.0   \n",
            "13428    2.1525         0.0           0  ...     13425.0  26.8  98.0   \n",
            "13429    2.3950         0.0           0  ...     13426.0  26.8  98.0   \n",
            "13430    2.7705         0.0           0  ...     13427.0  26.8  98.0   \n",
            "13431  153.7110         0.0           0  ...         NaN   NaN   NaN   \n",
            "\n",
            "       Pulse_Rate    SYS   DIA  Heart_rate  Resp_Rate   ST  Label  \n",
            "0             0.0    0.0   0.0         0.0        0.0  0.0    0.0  \n",
            "1             0.0    0.0   0.0        78.0       17.0  0.4    0.0  \n",
            "2           104.0    0.0   0.0        78.0       17.0  0.4    0.0  \n",
            "3           104.0    0.0   0.0        79.0       17.0  0.4    0.0  \n",
            "4           101.0    0.0   0.0        79.0       17.0  0.4    0.0  \n",
            "...           ...    ...   ...         ...        ...  ...    ...  \n",
            "13427        73.0  148.0  84.0        73.0       19.0  0.3    0.0  \n",
            "13428        73.0  148.0  84.0        73.0       19.0  0.3    0.0  \n",
            "13429        73.0  148.0  84.0        73.0       19.0  0.3    0.0  \n",
            "13430        73.0  148.0  84.0        73.0       19.0  0.3    0.0  \n",
            "13431         NaN    NaN   NaN         NaN        NaN  NaN    NaN  \n",
            "\n",
            "[13432 rows x 36 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df=df.replace('10.0.1.172',1)\n",
        "#df=df.replace('10.0.1.150',2)\n",
        "#df=df.replace('84:3a:4b:0f:5b:94',3)\n",
        "#df=df.replace('d8:9e:f3:95:02:75',4)\n",
        "#df=df.replace('b8:ca:3a:cf:0b:87',5)\n",
        "#df.head(2)\n",
        "#df.DstMac.unique()"
      ],
      "metadata": {
        "id": "d-oPTJNNnCD0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x1=df.SrcMac.unique()\n",
        "print(x1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl9wZ560u3e7",
        "outputId": "8e1504f5-8d69-4cd0-a578-309124055700"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes\n",
        "df.isnull().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccXeMFCJfSr8",
        "outputId": "50dd77d7-52fd-4c19-f98c-260d99804f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SrcBytes      0\n",
              "DstBytes      0\n",
              "SrcLoad       0\n",
              "DstLoad       0\n",
              "SrcGap        0\n",
              "DstGap        0\n",
              "SIntPkt       0\n",
              "DIntPkt       0\n",
              "SIntPktAct    0\n",
              "DIntPktAct    0\n",
              "SrcJitter     0\n",
              "DstJitter     0\n",
              "sMaxPktSz     0\n",
              "dMaxPktSz     0\n",
              "sMinPktSz     0\n",
              "dMinPktSz     0\n",
              "Dur           0\n",
              "Trans         0\n",
              "TotPkts       0\n",
              "TotBytes      0\n",
              "Load          0\n",
              "Loss          0\n",
              "pLoss         0\n",
              "pSrcLoss      0\n",
              "pDstLoss      0\n",
              "Rate          0\n",
              "Packet_num    0\n",
              "Temp          0\n",
              "SpO2          0\n",
              "Pulse_Rate    0\n",
              "SYS           0\n",
              "DIA           0\n",
              "Heart_rate    0\n",
              "Resp_Rate     0\n",
              "ST            0\n",
              "Label         0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "IvpdLZDhkizU",
        "outputId": "8f5d969e-608c-40e3-bf68-7e4721829ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SrcBytes  DstBytes   SrcLoad  DstLoad  SrcGap  DstGap   SIntPkt  DIntPkt  \\\n",
              "0       496       186  276914.0  92305.0       0       0  3.582333   1.9015   \n",
              "1       496       186  230984.0  76995.0       0       0  4.294667   2.9015   \n",
              "2       496       186  218470.0  72823.0       0       0  4.540667   3.2945   \n",
              "3       496       186  203376.0  67792.0       0       0  4.877667   3.3320   \n",
              "4       496       186  235723.0  78574.0       0       0  4.208333   2.8635   \n",
              "\n",
              "   SIntPktAct  DIntPktAct  ...  Packet_num  Temp  SpO2  Pulse_Rate  SYS  DIA  \\\n",
              "0         0.0           0  ...         1.0  28.9   0.0         0.0  0.0  0.0   \n",
              "1         0.0           0  ...         2.0  28.9   0.0         0.0  0.0  0.0   \n",
              "2         0.0           0  ...         3.0  28.9  89.0       104.0  0.0  0.0   \n",
              "3         0.0           0  ...         4.0  28.9  89.0       104.0  0.0  0.0   \n",
              "4         0.0           0  ...         5.0  28.9  89.0       101.0  0.0  0.0   \n",
              "\n",
              "   Heart_rate  Resp_Rate   ST  Label  \n",
              "0         0.0        0.0  0.0    0.0  \n",
              "1        78.0       17.0  0.4    0.0  \n",
              "2        78.0       17.0  0.4    0.0  \n",
              "3        79.0       17.0  0.4    0.0  \n",
              "4        79.0       17.0  0.4    0.0  \n",
              "\n",
              "[5 rows x 36 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e715996e-7c74-45ef-89f4-b22202ad7c18\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SrcBytes</th>\n",
              "      <th>DstBytes</th>\n",
              "      <th>SrcLoad</th>\n",
              "      <th>DstLoad</th>\n",
              "      <th>SrcGap</th>\n",
              "      <th>DstGap</th>\n",
              "      <th>SIntPkt</th>\n",
              "      <th>DIntPkt</th>\n",
              "      <th>SIntPktAct</th>\n",
              "      <th>DIntPktAct</th>\n",
              "      <th>...</th>\n",
              "      <th>Packet_num</th>\n",
              "      <th>Temp</th>\n",
              "      <th>SpO2</th>\n",
              "      <th>Pulse_Rate</th>\n",
              "      <th>SYS</th>\n",
              "      <th>DIA</th>\n",
              "      <th>Heart_rate</th>\n",
              "      <th>Resp_Rate</th>\n",
              "      <th>ST</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>276914.0</td>\n",
              "      <td>92305.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.582333</td>\n",
              "      <td>1.9015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>230984.0</td>\n",
              "      <td>76995.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.294667</td>\n",
              "      <td>2.9015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>218470.0</td>\n",
              "      <td>72823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.540667</td>\n",
              "      <td>3.2945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>203376.0</td>\n",
              "      <td>67792.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.877667</td>\n",
              "      <td>3.3320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>235723.0</td>\n",
              "      <td>78574.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.208333</td>\n",
              "      <td>2.8635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 36 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e715996e-7c74-45ef-89f4-b22202ad7c18')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e715996e-7c74-45ef-89f4-b22202ad7c18 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e715996e-7c74-45ef-89f4-b22202ad7c18');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = df.drop('Label', axis=1)\n",
        "y = dataset.Label\n",
        "X.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "bkCD1RvUFisG",
        "outputId": "83ab19e0-2735-4230-fdef-e72c0ab2d7cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   SrcBytes  DstBytes   SrcLoad  DstLoad  SrcGap  DstGap   SIntPkt  DIntPkt  \\\n",
              "0       496       186  276914.0  92305.0       0       0  3.582333   1.9015   \n",
              "1       496       186  230984.0  76995.0       0       0  4.294667   2.9015   \n",
              "2       496       186  218470.0  72823.0       0       0  4.540667   3.2945   \n",
              "3       496       186  203376.0  67792.0       0       0  4.877667   3.3320   \n",
              "4       496       186  235723.0  78574.0       0       0  4.208333   2.8635   \n",
              "\n",
              "   SIntPktAct  DIntPktAct  ...     Rate  Packet_num  Temp  SpO2  Pulse_Rate  \\\n",
              "0         0.0           0  ...  558.295         1.0  28.9   0.0         0.0   \n",
              "1         0.0           0  ...  465.694         2.0  28.9   0.0         0.0   \n",
              "2         0.0           0  ...  440.464         3.0  28.9  89.0       104.0   \n",
              "3         0.0           0  ...  410.032         4.0  28.9  89.0       104.0   \n",
              "4         0.0           0  ...  475.247         5.0  28.9  89.0       101.0   \n",
              "\n",
              "   SYS  DIA  Heart_rate  Resp_Rate   ST  \n",
              "0  0.0  0.0         0.0        0.0  0.0  \n",
              "1  0.0  0.0        78.0       17.0  0.4  \n",
              "2  0.0  0.0        78.0       17.0  0.4  \n",
              "3  0.0  0.0        79.0       17.0  0.4  \n",
              "4  0.0  0.0        79.0       17.0  0.4  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f25e8464-4c20-45d3-a948-51cbbdefa2f3\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SrcBytes</th>\n",
              "      <th>DstBytes</th>\n",
              "      <th>SrcLoad</th>\n",
              "      <th>DstLoad</th>\n",
              "      <th>SrcGap</th>\n",
              "      <th>DstGap</th>\n",
              "      <th>SIntPkt</th>\n",
              "      <th>DIntPkt</th>\n",
              "      <th>SIntPktAct</th>\n",
              "      <th>DIntPktAct</th>\n",
              "      <th>...</th>\n",
              "      <th>Rate</th>\n",
              "      <th>Packet_num</th>\n",
              "      <th>Temp</th>\n",
              "      <th>SpO2</th>\n",
              "      <th>Pulse_Rate</th>\n",
              "      <th>SYS</th>\n",
              "      <th>DIA</th>\n",
              "      <th>Heart_rate</th>\n",
              "      <th>Resp_Rate</th>\n",
              "      <th>ST</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>276914.0</td>\n",
              "      <td>92305.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3.582333</td>\n",
              "      <td>1.9015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>558.295</td>\n",
              "      <td>1.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>230984.0</td>\n",
              "      <td>76995.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.294667</td>\n",
              "      <td>2.9015</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>465.694</td>\n",
              "      <td>2.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>218470.0</td>\n",
              "      <td>72823.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.540667</td>\n",
              "      <td>3.2945</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>440.464</td>\n",
              "      <td>3.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>78.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>203376.0</td>\n",
              "      <td>67792.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.877667</td>\n",
              "      <td>3.3320</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>410.032</td>\n",
              "      <td>4.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>104.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>496</td>\n",
              "      <td>186</td>\n",
              "      <td>235723.0</td>\n",
              "      <td>78574.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4.208333</td>\n",
              "      <td>2.8635</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>475.247</td>\n",
              "      <td>5.0</td>\n",
              "      <td>28.9</td>\n",
              "      <td>89.0</td>\n",
              "      <td>101.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>17.0</td>\n",
              "      <td>0.4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 35 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f25e8464-4c20-45d3-a948-51cbbdefa2f3')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f25e8464-4c20-45d3-a948-51cbbdefa2f3 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f25e8464-4c20-45d3-a948-51cbbdefa2f3');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['SrcAddr'] = pd.to_numeric(df[\"SrcAddr\"],downcast='float')\n",
        "#df['SrcAddr'] = pd.to_numeric(df[\"SrcAddr\"],errors='coerce')\n",
        "#df['DstAddr'] = pd.to_numeric(df[\"DstAddr\"],errors='coerce')\n",
        "#df['Sport'] = pd.to_numeric(df[\"Sport\"],errors='coerce')\n",
        "#df['SrcMac'] = pd.to_numeric(df[\"SrcMac\"],errors='coerce')\n",
        "#df['DstMac'] = pd.to_numeric(df[\"DstMac\"],errors='coerce')\n",
        "#print(df.dtypes)\n",
        "#df.Sport.unique()\n",
        "#df['Sport']=df['Sport'].fillna(df['Sport'].mean())"
      ],
      "metadata": {
        "id": "oIZLrhA7gPWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split dataset into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(df.drop('Label', axis=1),\n",
        "                                                    df['Label'], test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "MF45q3vCwTe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "PXhljA_BFYTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "# Train an SVM classifier on the training set\n",
        "cl = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "cl.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "y_pred5 = cl.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred5)\n",
        "\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9UQ7M1KZMfR8",
        "outputId": "af7959a9-ebc6-4b6c-febc-2ddcb158dc33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9255514705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred5)\n",
        "accuracy = cl.score(X_test, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcaCaR06M2Yo",
        "outputId": "8d16c858-31d1-40b5-cce6-4e0ce5177e6b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93489085 0.92837993 0.93527384 0.94101877 0.93639847]\n",
            "Mean cross-validation score: 0.9351923706217873\n",
            "Test set accuracy: 0.925551\n",
            "Sensitivity:  [0.99473315 0.45192308]\n",
            "Specificity:  [-0.05766871 -0.8690184 ]\n",
            "Best hyperparameters:  {'learning_rate_init': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "#sc = StandardScaler()\n",
        "#X_train = sc.fit_transform(X_train)\n",
        "#X_test = sc.transform(X_test)"
      ],
      "metadata": {
        "id": "DITHH5m0wWj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "#Start time\n",
        "start_time = time.time()\n",
        "\n",
        "# Train model\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50, 50,50,50), max_iter=500, alpha=0.0001,\n",
        "                    verbose=10,  random_state=5, tol=0.000000001)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "# Print time taken\n",
        "print(\"Time taken to train model: {:.2f} seconds\".format(end_time - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23cOA9iswbDk",
        "outputId": "2383f13d-b313-47f1-b8f3-19957e0637cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 7.02541387\n",
            "Iteration 2, loss = 5.82751466\n",
            "Iteration 3, loss = 5.37640987\n",
            "Iteration 4, loss = 5.09577484\n",
            "Iteration 5, loss = 5.61431990\n",
            "Iteration 6, loss = 5.53078896\n",
            "Iteration 7, loss = 5.34090320\n",
            "Iteration 8, loss = 5.10821080\n",
            "Iteration 9, loss = 4.75807392\n",
            "Iteration 10, loss = 4.63438301\n",
            "Iteration 11, loss = 4.81769661\n",
            "Iteration 12, loss = 4.47243582\n",
            "Iteration 13, loss = 4.80902244\n",
            "Iteration 14, loss = 4.53912900\n",
            "Iteration 15, loss = 4.77797534\n",
            "Iteration 16, loss = 4.77712058\n",
            "Iteration 17, loss = 4.14206966\n",
            "Iteration 18, loss = 4.56095327\n",
            "Iteration 19, loss = 4.41799239\n",
            "Iteration 20, loss = 4.39183109\n",
            "Iteration 21, loss = 3.42978294\n",
            "Iteration 22, loss = 4.52738894\n",
            "Iteration 23, loss = 4.15243018\n",
            "Iteration 24, loss = 4.27796251\n",
            "Iteration 25, loss = 4.15930506\n",
            "Iteration 26, loss = 5.83241303\n",
            "Iteration 27, loss = 5.05753269\n",
            "Iteration 28, loss = 4.16412555\n",
            "Iteration 29, loss = 3.98564982\n",
            "Iteration 30, loss = 4.14012473\n",
            "Iteration 31, loss = 3.50390473\n",
            "Iteration 32, loss = 3.04952064\n",
            "Iteration 33, loss = 3.31868698\n",
            "Iteration 34, loss = 3.55901107\n",
            "Iteration 35, loss = 3.48791551\n",
            "Iteration 36, loss = 3.41241940\n",
            "Iteration 37, loss = 2.77330122\n",
            "Iteration 38, loss = 2.99827295\n",
            "Iteration 39, loss = 2.63705497\n",
            "Iteration 40, loss = 2.66495038\n",
            "Iteration 41, loss = 2.46871624\n",
            "Iteration 42, loss = 2.46127150\n",
            "Iteration 43, loss = 2.32026391\n",
            "Iteration 44, loss = 1.33035840\n",
            "Iteration 45, loss = 2.06863149\n",
            "Iteration 46, loss = 1.68461984\n",
            "Iteration 47, loss = 2.02534744\n",
            "Iteration 48, loss = 1.50132816\n",
            "Iteration 49, loss = 1.92738971\n",
            "Iteration 50, loss = 2.12633350\n",
            "Iteration 51, loss = 1.46867545\n",
            "Iteration 52, loss = 2.20349191\n",
            "Iteration 53, loss = 1.91228489\n",
            "Iteration 54, loss = 1.44410229\n",
            "Iteration 55, loss = 0.38393883\n",
            "Iteration 56, loss = 0.43317118\n",
            "Iteration 57, loss = 0.29658579\n",
            "Iteration 58, loss = 0.29459090\n",
            "Iteration 59, loss = 0.44686737\n",
            "Iteration 60, loss = 0.29920300\n",
            "Iteration 61, loss = 0.29731038\n",
            "Iteration 62, loss = 0.53941196\n",
            "Iteration 63, loss = 0.88786179\n",
            "Iteration 64, loss = 0.59363671\n",
            "Iteration 65, loss = 0.57544991\n",
            "Iteration 66, loss = 0.29579530\n",
            "Iteration 67, loss = 0.28292770\n",
            "Iteration 68, loss = 0.31902799\n",
            "Iteration 69, loss = 0.28662811\n",
            "Iteration 70, loss = 0.28091049\n",
            "Iteration 71, loss = 0.27785336\n",
            "Iteration 72, loss = 0.28596059\n",
            "Iteration 73, loss = 0.30285475\n",
            "Iteration 74, loss = 0.29871085\n",
            "Iteration 75, loss = 0.26824669\n",
            "Iteration 76, loss = 0.31816836\n",
            "Iteration 77, loss = 0.26858172\n",
            "Iteration 78, loss = 0.28049963\n",
            "Iteration 79, loss = 0.27997791\n",
            "Iteration 80, loss = 0.26307810\n",
            "Iteration 81, loss = 0.26124211\n",
            "Iteration 82, loss = 0.33558453\n",
            "Iteration 83, loss = 0.28232938\n",
            "Iteration 84, loss = 0.26523307\n",
            "Iteration 85, loss = 0.32131695\n",
            "Iteration 86, loss = 0.27821483\n",
            "Iteration 87, loss = 0.30076129\n",
            "Iteration 88, loss = 0.28344616\n",
            "Iteration 89, loss = 2.09261033\n",
            "Iteration 90, loss = 6.16553418\n",
            "Iteration 91, loss = 5.99226238\n",
            "Iteration 92, loss = 5.07839055\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Time taken to train model: 17.77 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Evaluate model\n",
        "#accuracy = clf.score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QVyZNptCd0k",
        "outputId": "48a8c9ee-9ebc-4707-995d-46c3271e69a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 92.89%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "print(\"Sensitivity:\", sensitivity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQlfUvk34-xe",
        "outputId": "eb930077-2cdd-4dcb-c632-088799126e57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity: 0.13930348258706468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Calculate the confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calculate the specificity score\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcDGqXYk5R-3",
        "outputId": "a443c1ae-977c-4fe5-ac65-64c2e40273f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity: 0.9940600978336828\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN\n"
      ],
      "metadata": {
        "id": "ye4XIx6Bgq8K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create a KNN classifier with k=18\n",
        "knn = KNeighborsClassifier(n_neighbors=18)\n",
        "\n",
        "# Train the model on the training set\n",
        "knn.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = knn.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = knn.score(X_test_pca, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFkaKobg56p6",
        "outputId": "afea0376-e6ca-4802-e8a3-71740720de48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8725490196078431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2GjPnWL6k2b",
        "outputId": "88db4b3e-a97f-4c60-bbe5-32a947c18eb0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.02570007,  -0.05829246,   0.81666448, ..., -10.59686476,\n",
              "         -2.46008006,  -2.2115606 ],\n",
              "       [ -0.02570007,  -0.05829246,   0.22420263, ...,   0.28759797,\n",
              "         -0.35268602,   1.34142235],\n",
              "       [ -0.02570007,  -0.05829246,   0.06278161, ...,   0.28759797,\n",
              "         -0.35268602,   1.34142235],\n",
              "       ...,\n",
              "       [ -0.02570007,  -0.05829246,   0.16082869, ...,  -0.410124  ,\n",
              "         -0.10475731,   0.45317661],\n",
              "       [ -0.02570007,  -0.05829246,   0.90837804, ...,  -0.410124  ,\n",
              "         -0.10475731,   0.45317661],\n",
              "       [ -0.02570007,  -0.05829246,  -2.63420327, ...,          nan,\n",
              "                 nan,          nan]])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca = PCA(0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "bgF0GQIvHOtI",
        "outputId": "86c744da-c360-444e-f5c4-f747baad8144"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-aca075241836>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.95\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0mU\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_components_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/decomposition/_pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    483\u001b[0m             )\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    486\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    566\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 921\u001b[0;31m             _assert_all_finite(\n\u001b[0m\u001b[1;32m    922\u001b[0m                 \u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m                 \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[0m\n\u001b[1;32m    159\u001b[0m                 \u001b[0;34m\"#estimators-that-handle-nan-values\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m             )\n\u001b[0;32m--> 161\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_err\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Input X contains NaN.\nPCA does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_pca"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mrwaaHGmNio0",
        "outputId": "546db824-e6c0-4f36-e4e3-b22483c89295"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.06057295e-01,  1.50251100e-02,  1.40529581e+00, ...,\n",
              "         1.03290153e+01,  1.59880291e+01, -3.71995806e+00],\n",
              "       [-2.90542830e-02, -3.81673475e-01,  1.16083179e+00, ...,\n",
              "         5.67207318e+00,  2.32837659e+01, -5.77384631e+00],\n",
              "       [-1.33202997e-01, -7.87851824e-02,  9.20050859e-01, ...,\n",
              "        -1.75635764e-01, -3.86600539e-01, -5.05544552e-01],\n",
              "       ...,\n",
              "       [-4.44631486e-01,  8.22133274e-01,  6.27182118e-01, ...,\n",
              "        -2.20844614e+00,  3.11289543e-01, -2.77865050e-01],\n",
              "       [-2.94866059e-01,  2.86886433e-01,  5.56570130e-02, ...,\n",
              "        -1.32928614e-01,  4.04837800e-01, -2.28294464e-01],\n",
              "       [-4.17862391e-01,  7.43577989e-01,  5.31681251e-01, ...,\n",
              "        -2.61188196e-01,  3.96635127e-01, -2.18341867e-01]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca.n_components_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T83RNYLmIUUb",
        "outputId": "e3e8bacc-6c5d-4da3-f06e-44193cbb8f4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "14"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8LUbdrTRJoZF",
        "outputId": "ec7c38ef-026e-4544-b021-6e00eb1ef05d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24290965, 0.14408942, 0.12169736, 0.08413514, 0.08280942,\n",
              "       0.05973078, 0.03950558, 0.03710242, 0.03333447, 0.03179337,\n",
              "       0.02660276, 0.02336481, 0.01616186, 0.01550787])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "NnRyEN-yImz-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "# Define the parameter grid to search over\n",
        "param_grid = {\n",
        "    'learning_rate_init': [0.001, 0.01, 0.1],\n",
        "}\n",
        "\n",
        "# Train an MLP classifier with GridSearchCV and learning rate hyperparameter\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50, 50, 50, 50), max_iter=20, alpha=0.0001,\n",
        "                    verbose=10, random_state=5, tol=0.000000001,\n",
        "                    activation='relu', solver='adam', batch_size=64)\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train_pca, y_train)\n",
        "\n",
        "# Evaluate the trained model\n",
        "score = grid_search.score(X_test_pca, y_test)\n",
        "print(\"Test set score: %f\" % score)\n",
        "\n",
        "# Print the best hyperparameters found by GridSearchCV\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ29_yz-Hdlo",
        "outputId": "d6f85e50-d6e5-4bfc-b226-b8493d8de22b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31913954\n",
            "Iteration 2, loss = 0.24917893\n",
            "Iteration 3, loss = 0.23454951\n",
            "Iteration 4, loss = 0.22478006\n",
            "Iteration 5, loss = 0.21786061\n",
            "Iteration 6, loss = 0.21214965\n",
            "Iteration 7, loss = 0.21169689\n",
            "Iteration 8, loss = 0.20251063\n",
            "Iteration 9, loss = 0.19886334\n",
            "Iteration 10, loss = 0.19708654\n",
            "Iteration 11, loss = 0.19137171\n",
            "Iteration 12, loss = 0.18787198\n",
            "Iteration 13, loss = 0.18584792\n",
            "Iteration 14, loss = 0.18329841\n",
            "Iteration 15, loss = 0.17948354\n",
            "Iteration 16, loss = 0.17641534\n",
            "Iteration 17, loss = 0.17246807\n",
            "Iteration 18, loss = 0.17433654\n",
            "Iteration 19, loss = 0.16733546\n",
            "Iteration 20, loss = 0.16530414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31864386\n",
            "Iteration 2, loss = 0.24992970\n",
            "Iteration 3, loss = 0.23259075\n",
            "Iteration 4, loss = 0.22541621\n",
            "Iteration 5, loss = 0.21899220\n",
            "Iteration 6, loss = 0.21364271\n",
            "Iteration 7, loss = 0.21092245\n",
            "Iteration 8, loss = 0.20559803\n",
            "Iteration 9, loss = 0.20302833\n",
            "Iteration 10, loss = 0.19843973\n",
            "Iteration 11, loss = 0.19190629\n",
            "Iteration 12, loss = 0.19301795\n",
            "Iteration 13, loss = 0.18677544\n",
            "Iteration 14, loss = 0.18391379\n",
            "Iteration 15, loss = 0.18482877\n",
            "Iteration 16, loss = 0.18066266\n",
            "Iteration 17, loss = 0.17867529\n",
            "Iteration 18, loss = 0.17178342\n",
            "Iteration 19, loss = 0.16910971\n",
            "Iteration 20, loss = 0.16934861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31913016\n",
            "Iteration 2, loss = 0.24998555\n",
            "Iteration 3, loss = 0.23052037\n",
            "Iteration 4, loss = 0.22332313\n",
            "Iteration 5, loss = 0.21773875\n",
            "Iteration 6, loss = 0.21127779\n",
            "Iteration 7, loss = 0.20878148\n",
            "Iteration 8, loss = 0.20228614\n",
            "Iteration 9, loss = 0.19918886\n",
            "Iteration 10, loss = 0.19307298\n",
            "Iteration 11, loss = 0.18845221\n",
            "Iteration 12, loss = 0.18657235\n",
            "Iteration 13, loss = 0.18819953\n",
            "Iteration 14, loss = 0.18041276\n",
            "Iteration 15, loss = 0.17947999\n",
            "Iteration 16, loss = 0.17629629\n",
            "Iteration 17, loss = 0.16997777\n",
            "Iteration 18, loss = 0.16895922\n",
            "Iteration 19, loss = 0.16663064\n",
            "Iteration 20, loss = 0.16507819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.28599752\n",
            "Iteration 2, loss = 0.24383371\n",
            "Iteration 3, loss = 0.23458845\n",
            "Iteration 4, loss = 0.23199733\n",
            "Iteration 5, loss = 0.22511441\n",
            "Iteration 6, loss = 0.21938460\n",
            "Iteration 7, loss = 0.22456756\n",
            "Iteration 8, loss = 0.21721394\n",
            "Iteration 9, loss = 0.21241837\n",
            "Iteration 10, loss = 0.20783343\n",
            "Iteration 11, loss = 0.20315551\n",
            "Iteration 12, loss = 0.20000406\n",
            "Iteration 13, loss = 0.20077325\n",
            "Iteration 14, loss = 0.19540601\n",
            "Iteration 15, loss = 0.19366102\n",
            "Iteration 16, loss = 0.18665249\n",
            "Iteration 17, loss = 0.18804961\n",
            "Iteration 18, loss = 0.18429461\n",
            "Iteration 19, loss = 0.17891601\n",
            "Iteration 20, loss = 0.18174052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.29269731\n",
            "Iteration 2, loss = 0.23939370\n",
            "Iteration 3, loss = 0.23824443\n",
            "Iteration 4, loss = 0.23287711\n",
            "Iteration 5, loss = 0.23155934\n",
            "Iteration 6, loss = 0.22251650\n",
            "Iteration 7, loss = 0.21858058\n",
            "Iteration 8, loss = 0.21502759\n",
            "Iteration 9, loss = 0.22198159\n",
            "Iteration 10, loss = 0.21163829\n",
            "Iteration 11, loss = 0.20499581\n",
            "Iteration 12, loss = 0.20951443\n",
            "Iteration 13, loss = 0.20127136\n",
            "Iteration 14, loss = 0.19936484\n",
            "Iteration 15, loss = 0.19850301\n",
            "Iteration 16, loss = 0.19397274\n",
            "Iteration 17, loss = 0.18849428\n",
            "Iteration 18, loss = 0.19045300\n",
            "Iteration 19, loss = 0.18704501\n",
            "Iteration 20, loss = 0.18684157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.28729193\n",
            "Iteration 2, loss = 0.24374669\n",
            "Iteration 3, loss = 0.22776203\n",
            "Iteration 4, loss = 0.22549575\n",
            "Iteration 5, loss = 0.22164580\n",
            "Iteration 6, loss = 0.21654776\n",
            "Iteration 7, loss = 0.20951162\n",
            "Iteration 8, loss = 0.21365650\n",
            "Iteration 9, loss = 0.20912322\n",
            "Iteration 10, loss = 0.20067303\n",
            "Iteration 11, loss = 0.20113461\n",
            "Iteration 12, loss = 0.19600083\n",
            "Iteration 13, loss = 0.20174325\n",
            "Iteration 14, loss = 0.20228236\n",
            "Iteration 15, loss = 0.21441251\n",
            "Iteration 16, loss = 0.20284158\n",
            "Iteration 17, loss = 0.19407193\n",
            "Iteration 18, loss = 0.18908267\n",
            "Iteration 19, loss = 0.18305167\n",
            "Iteration 20, loss = 0.18256161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.40357121\n",
            "Iteration 2, loss = 0.26061648\n",
            "Iteration 3, loss = 0.25289995\n",
            "Iteration 4, loss = 0.36286153\n",
            "Iteration 5, loss = 0.34486994\n",
            "Iteration 6, loss = 0.32011537\n",
            "Iteration 7, loss = 0.33605219\n",
            "Iteration 8, loss = 0.32277305\n",
            "Iteration 9, loss = 0.29054770\n",
            "Iteration 10, loss = 0.27005832\n",
            "Iteration 11, loss = 0.30126759\n",
            "Iteration 12, loss = 0.26393543\n",
            "Iteration 13, loss = 0.26376698\n",
            "Iteration 14, loss = 0.26594452\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.39100688\n",
            "Iteration 2, loss = 0.35321494\n",
            "Iteration 3, loss = 0.34616225\n",
            "Iteration 4, loss = 0.36315051\n",
            "Iteration 5, loss = 0.35644259\n",
            "Iteration 6, loss = 0.36381144\n",
            "Iteration 7, loss = 0.37513404\n",
            "Iteration 8, loss = 0.37209841\n",
            "Iteration 9, loss = 0.35262329\n",
            "Iteration 10, loss = 0.34717676\n",
            "Iteration 11, loss = 0.33690714\n",
            "Iteration 12, loss = 0.33751322\n",
            "Iteration 13, loss = 0.33786566\n",
            "Iteration 14, loss = 0.35008250\n",
            "Iteration 15, loss = 0.36421837\n",
            "Iteration 16, loss = 0.36358334\n",
            "Iteration 17, loss = 0.36431911\n",
            "Iteration 18, loss = 0.36377704\n",
            "Iteration 19, loss = 0.36432864\n",
            "Iteration 20, loss = 0.36528968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.34125687\n",
            "Iteration 2, loss = 0.40147802\n",
            "Iteration 3, loss = 0.38158777\n",
            "Iteration 4, loss = 0.38163470\n",
            "Iteration 5, loss = 0.38196617\n",
            "Iteration 6, loss = 0.38159858\n",
            "Iteration 7, loss = 0.38210711\n",
            "Iteration 8, loss = 0.38128102\n",
            "Iteration 9, loss = 0.38067922\n",
            "Iteration 10, loss = 0.38067514\n",
            "Iteration 11, loss = 0.38051906\n",
            "Iteration 12, loss = 0.38107484\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.29378767\n",
            "Iteration 2, loss = 0.23786850\n",
            "Iteration 3, loss = 0.22287776\n",
            "Iteration 4, loss = 0.21734769\n",
            "Iteration 5, loss = 0.21076838\n",
            "Iteration 6, loss = 0.20386627\n",
            "Iteration 7, loss = 0.20083564\n",
            "Iteration 8, loss = 0.19531344\n",
            "Iteration 9, loss = 0.19238007\n",
            "Iteration 10, loss = 0.18659015\n",
            "Iteration 11, loss = 0.18368471\n",
            "Iteration 12, loss = 0.17862524\n",
            "Iteration 13, loss = 0.17454521\n",
            "Iteration 14, loss = 0.17133331\n",
            "Iteration 15, loss = 0.16919724\n",
            "Iteration 16, loss = 0.16638101\n",
            "Iteration 17, loss = 0.16292259\n",
            "Iteration 18, loss = 0.16046437\n",
            "Iteration 19, loss = 0.15932335\n",
            "Iteration 20, loss = 0.15930443\n",
            "Test set score: 0.935049\n",
            "Best hyperparameters:  {'learning_rate_init': 0.001}\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "\n",
        "# Evaluate model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: {:.2f}%\".format(accuracy*100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ot3UK2iqJXh4",
        "outputId": "3dd74246-2792-4f9c-d8b2-64c317daf0cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 94.39%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import recall_score\n",
        "sensitivity = recall_score(y_test, y_pred, pos_label=1)\n",
        "print(\"Sensitivity:\", sensitivity)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XwJE27b3xYs",
        "outputId": "89b1ce95-3d50-4d54-d0ab-62a752967d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sensitivity: 0.6169154228855721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Calculate the confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
        "\n",
        "# Calculate the specificity score\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F964CmhB4pqu",
        "outputId": "7eef53c9-25cb-4e45-915f-bcb419466b15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity: 0.9898672257162823\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca.explained_variance_ratio_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DvOiKJ3YJjcU",
        "outputId": "207ac450-675b-46a3-dfc4-8cb459857262"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.24290965, 0.14408942, 0.12169736, 0.08413514, 0.08280942,\n",
              "       0.05973078, 0.03950558, 0.03710242, 0.03333447, 0.03179337,\n",
              "       0.02660276, 0.02336481, 0.01616186, 0.01550787])"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create a KNN classifier with k=18\n",
        "knn = KNeighborsClassifier(n_neighbors=18)\n",
        "\n",
        "# Train the model on the training set\n",
        "knn.fit(X_train_pca, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = knn.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = knn.score(X_test_pca, y_test)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJzOpot0G60s",
        "outputId": "dd243976-9950-4e6e-c83e-87a0fb944180"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.930453431372549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "# Create a KNN classifier with k=18\n",
        "knn = KNeighborsClassifier(n_neighbors=18)\n",
        "\n",
        "# Train the model on the training set\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Predict the labels of the test set\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V09H0iH_7Eoo",
        "outputId": "5ec4fdc5-579f-4061-9d0d-078c458711a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9255514705882353\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn import svm\n",
        "\n",
        "\n",
        "# Train an SVM classifier on the training set\n",
        "clf = svm.SVC(kernel='linear', C=1, random_state=42)\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzK3Nf91M3Q8",
        "outputId": "423d754c-9263-4ae1-e324-33161f7cb75a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9249387254901961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "X_scaled"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ibMzsx-WRePA",
        "outputId": "6701059f-ca02-45bc-d336-9a9e066224b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ -0.0227494 ,  -0.05766847,   0.81928062, ..., -11.41550613,\n",
              "         -2.68858057,  -2.48138523],\n",
              "       [ -0.0227494 ,  -0.05766847,   0.24101703, ...,   0.38676231,\n",
              "         -0.36796157,   1.36561766],\n",
              "       [ -0.0227494 ,  -0.05766847,   0.08346444, ...,   0.38676231,\n",
              "         -0.36796157,   1.36561766],\n",
              "       ...,\n",
              "       [ -0.0227494 ,  -0.05766847,   0.96600572, ...,  -0.36979336,\n",
              "         -0.09494757,   0.40386693],\n",
              "       [ -0.0227494 ,  -0.05766847,   0.32676824, ...,  -0.36979336,\n",
              "         -0.09494757,   0.40386693],\n",
              "       [ -0.0227494 ,  -0.05766847,   0.84214425, ...,  -0.36979336,\n",
              "         -0.09494757,   0.40386693]])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pca = PCA(0.95)\n",
        "X_pca = pca.fit_transform(X_scaled)\n",
        "X_pca.shape"
      ],
      "metadata": {
        "id": "GC3R8UlHtjCm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62f5cc18-4637-48d0-fefe-b898b27bd32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16318, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the number of features before and after encoding\n",
        "num_features_before_encoding = 36\n",
        "num_features_after_encoding = 14\n",
        "\n",
        "# Compute the number of features retained and discarded\n",
        "num_features_retained = num_features_after_encoding\n",
        "num_features_discarded = num_features_before_encoding - num_features_after_encoding\n",
        "\n",
        "# Create labels for the pie chart\n",
        "labels = ['Retained Features', 'Discarded Features']\n",
        "\n",
        "# Create sizes for the pie chart\n",
        "sizes = [num_features_retained, num_features_discarded]\n",
        "\n",
        "# Create colors for the pie chart\n",
        "colors = ['green', 'red']\n",
        "\n",
        "# Create values for the pie chart\n",
        "values = [num_features_retained, num_features_discarded]\n",
        "\n",
        "# Plot the pie chart\n",
        "plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
        "plt.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle\n",
        "plt.title('Reduction of Features after Encoding')\n",
        "\n",
        "# Add values to the segments of the pie chart\n",
        "for i, value in enumerate(values):\n",
        "    plt.text(0.5 * (i - 0.5), 0, str(value), color='white', fontweight='bold', ha='center', va='center')\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "id": "z58ZG1CO-jim",
        "outputId": "e6ec01a9-2b7c-46d2-b54a-5e6cb6497544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "input_file = '/content/wustl-ehms-2020.csv'  # Path to the input CSV file\n",
        "output_directory = '/content/1.csv'  # Path to the output directory where split files will be saved\n",
        "columns_to_split = ['Dir', 'Packet_num']  # Specify the columns to split on\n",
        "\n",
        "# Read the input CSV file into a DataFrame\n",
        "df = pd.read_csv(input_file)\n",
        "\n",
        "# Iterate over the unique combinations of values in the specified columns\n",
        "for _, group in df.groupby(columns_to_split):\n",
        "    # Generate a unique filename based on the column values\n",
        "    filename = '_'.join(str(val) for val in group.iloc[0][columns_to_split]) + '.csv'\n",
        "    output_file = output_directory + filename\n",
        "\n",
        "    # Save the grouped data as a separate CSV file\n",
        "    group.to_csv(output_file, index=False)\n",
        "\n",
        "print(\"CSV file splitting complete.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CCNo-0ilq4Vb",
        "outputId": "ea1c4159-50e8-4324-92c5-3a312e846a6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV file splitting complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Define the parameters for input layer, hidden layer, and output layer\n",
        "input_layer_size = X.shape[1]  # Number of features in the input data\n",
        "hidden_layer_sizes = (100, 50)  # Size of each hidden layer\n",
        "output_layer_size = len(y.unique())  # Number of classes in the output (i.e., number of neurons in the output layer)\n",
        "import time\n",
        "#Start time\n",
        "start_time = time.time()\n",
        "# Create the MLP classifier with the specified layer sizes\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation='relu', solver='adam', max_iter=500)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation on the training data\n",
        "k = 5  # number of folds\n",
        "scores = cross_val_score(mlp_classifier, X_train, y_train, cv=k)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Train the classifier on the full training set\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "# End time\n",
        "end_time = time.time()\n",
        "# Print time taken\n",
        "print(\"Time taken to train model: {:.2f} seconds\".format(end_time - start_time))\n",
        "# Evaluate the classifier on the testing set\n",
        "score = mlp_classifier.score(X_test, y_test)\n",
        "\n",
        "print(\"Average cross-validation accuracy: {:.2f}\".format(scores.mean()))\n",
        "print(\"Testing accuracy: {:.2f}\".format(score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joWHJcaGG8PK",
        "outputId": "731fec34-73e3-455f-bb69-ef2c7735d74e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 7.56992455\n",
            "Iteration 2, loss = 5.92078998\n",
            "Iteration 3, loss = 5.40999195\n",
            "Iteration 4, loss = 5.69510345\n",
            "Iteration 5, loss = 5.00958827\n",
            "Iteration 6, loss = 4.84724470\n",
            "Iteration 7, loss = 5.10889102\n",
            "Iteration 8, loss = 5.18258025\n",
            "Iteration 9, loss = 5.32054212\n",
            "Iteration 10, loss = 4.94161732\n",
            "Iteration 11, loss = 4.80192921\n",
            "Iteration 12, loss = 4.48279439\n",
            "Iteration 13, loss = 4.62499284\n",
            "Iteration 14, loss = 4.65805370\n",
            "Iteration 15, loss = 4.49946378\n",
            "Iteration 16, loss = 3.92993915\n",
            "Iteration 17, loss = 4.17708591\n",
            "Iteration 18, loss = 4.44195968\n",
            "Iteration 19, loss = 3.83410377\n",
            "Iteration 20, loss = 3.92259130\n",
            "Iteration 21, loss = 4.09856110\n",
            "Iteration 22, loss = 3.82643138\n",
            "Iteration 23, loss = 3.82142756\n",
            "Iteration 24, loss = 3.82785512\n",
            "Iteration 25, loss = 3.47254868\n",
            "Iteration 26, loss = 4.23170945\n",
            "Iteration 27, loss = 3.94111104\n",
            "Iteration 28, loss = 3.17079667\n",
            "Iteration 29, loss = 3.13351179\n",
            "Iteration 30, loss = 3.16338692\n",
            "Iteration 31, loss = 2.96654721\n",
            "Iteration 32, loss = 2.50635348\n",
            "Iteration 33, loss = 2.75469379\n",
            "Iteration 34, loss = 2.50730468\n",
            "Iteration 35, loss = 2.39960302\n",
            "Iteration 36, loss = 2.18288380\n",
            "Iteration 37, loss = 2.30759131\n",
            "Iteration 38, loss = 2.01761679\n",
            "Iteration 39, loss = 2.52422981\n",
            "Iteration 40, loss = 3.08607291\n",
            "Iteration 41, loss = 4.37191319\n",
            "Iteration 42, loss = 4.08803355\n",
            "Iteration 43, loss = 3.72180517\n",
            "Iteration 44, loss = 3.52025896\n",
            "Iteration 45, loss = 2.40898141\n",
            "Iteration 46, loss = 1.78656476\n",
            "Iteration 47, loss = 2.46342835\n",
            "Iteration 48, loss = 2.36865655\n",
            "Iteration 49, loss = 1.49309783\n",
            "Iteration 50, loss = 1.55483409\n",
            "Iteration 51, loss = 0.98384674\n",
            "Iteration 52, loss = 1.47240801\n",
            "Iteration 53, loss = 1.01410951\n",
            "Iteration 54, loss = 0.72896692\n",
            "Iteration 55, loss = 0.29048112\n",
            "Iteration 56, loss = 0.29022838\n",
            "Iteration 57, loss = 0.28679899\n",
            "Iteration 58, loss = 0.28375814\n",
            "Iteration 59, loss = 0.27798740\n",
            "Iteration 60, loss = 0.30925493\n",
            "Iteration 61, loss = 0.27853125\n",
            "Iteration 62, loss = 0.32469433\n",
            "Iteration 63, loss = 0.53462827\n",
            "Iteration 64, loss = 0.29586304\n",
            "Iteration 65, loss = 0.27912654\n",
            "Iteration 66, loss = 0.27597305\n",
            "Iteration 67, loss = 0.27749943\n",
            "Iteration 68, loss = 0.27227886\n",
            "Iteration 69, loss = 0.27586684\n",
            "Iteration 70, loss = 0.27974125\n",
            "Iteration 71, loss = 0.27755437\n",
            "Iteration 72, loss = 0.27610122\n",
            "Iteration 73, loss = 0.28316128\n",
            "Iteration 74, loss = 0.31444155\n",
            "Iteration 75, loss = 0.28551173\n",
            "Iteration 76, loss = 0.28284225\n",
            "Iteration 77, loss = 0.27067866\n",
            "Iteration 78, loss = 0.28934862\n",
            "Iteration 79, loss = 0.54033560\n",
            "Iteration 80, loss = 5.42863198\n",
            "Iteration 81, loss = 2.69110914\n",
            "Iteration 82, loss = 2.51123716\n",
            "Iteration 83, loss = 1.04219850\n",
            "Iteration 84, loss = 1.42840438\n",
            "Iteration 85, loss = 0.31369980\n",
            "Iteration 86, loss = 0.26864650\n",
            "Iteration 87, loss = 0.26454644\n",
            "Iteration 88, loss = 0.29459680\n",
            "Iteration 89, loss = 0.26662957\n",
            "Iteration 90, loss = 0.26145148\n",
            "Iteration 91, loss = 0.27007739\n",
            "Iteration 92, loss = 0.27238107\n",
            "Iteration 93, loss = 0.27412401\n",
            "Iteration 94, loss = 0.28226325\n",
            "Iteration 95, loss = 0.27287562\n",
            "Iteration 96, loss = 0.26493082\n",
            "Iteration 97, loss = 0.25293165\n",
            "Iteration 98, loss = 0.27644447\n",
            "Iteration 99, loss = 0.36034936\n",
            "Iteration 100, loss = 2.40715319\n",
            "Iteration 101, loss = 0.97407180\n",
            "Iteration 102, loss = 0.59492092\n",
            "Iteration 103, loss = 0.41342102\n",
            "Iteration 104, loss = 0.32994339\n",
            "Iteration 105, loss = 0.29119699\n",
            "Iteration 106, loss = 0.26803024\n",
            "Iteration 107, loss = 0.26054457\n",
            "Iteration 108, loss = 0.25576653\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Time taken to train model: 61.34 seconds\n",
            "Average cross-validation accuracy: 0.76\n",
            "Testing accuracy: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "\n",
        "# Define the parameters for input layer, hidden layer, and output layer\n",
        "input_layer_size = X.shape[1]  # Number of features in the input data\n",
        "hidden_layer_sizes = (100, 50)  # Size of each hidden layer\n",
        "output_layer_size = len(y.unique())  # Number of classes in the output (i.e., number of neurons in the output layer)\n",
        "import time\n",
        "#Start time\n",
        "start_time = time.time()\n",
        "# Create the MLP classifier with the specified layer sizes\n",
        "mlp_classifier = MLPClassifier(hidden_layer_sizes=hidden_layer_sizes, activation='relu', solver='adam', max_iter=500)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Perform k-fold cross-validation on the training data\n",
        "k = 5  # number of folds\n",
        "scores = cross_val_score(mlp_classifier, X_train, y_train, cv=k)\n",
        "\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# End time\n",
        "end_time = time.time()\n",
        "# Print time taken\n",
        "print(\"Time taken to train model: {:.2f} seconds\".format(end_time - start_time))\n",
        "\n",
        "# Train the classifier on the full training set\n",
        "mlp_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "score = mlp_classifier.score(X_test, y_test)\n",
        "\n",
        "print(\"Average cross-validation accuracy: {:.2f}\".format(scores.mean()))\n",
        "print(\"Testing accuracy: {:.2f}\".format(score))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "igiOog5nW-8A",
        "outputId": "f339ba5a-8695-45e5-e31d-f638bc053846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.34498305\n",
            "Iteration 2, loss = 0.26130436\n",
            "Iteration 3, loss = 0.23777956\n",
            "Iteration 4, loss = 0.22856495\n",
            "Iteration 5, loss = 0.22042747\n",
            "Iteration 6, loss = 0.21444204\n",
            "Iteration 7, loss = 0.20872061\n",
            "Iteration 8, loss = 0.20526411\n",
            "Iteration 9, loss = 0.19989884\n",
            "Iteration 10, loss = 0.19695656\n",
            "Iteration 11, loss = 0.19366645\n",
            "Iteration 12, loss = 0.18949201\n",
            "Iteration 13, loss = 0.18750968\n",
            "Iteration 14, loss = 0.18446035\n",
            "Iteration 15, loss = 0.18110066\n",
            "Iteration 16, loss = 0.18094116\n",
            "Iteration 17, loss = 0.17668038\n",
            "Iteration 18, loss = 0.17441097\n",
            "Iteration 19, loss = 0.17060632\n",
            "Iteration 20, loss = 0.16977901\n",
            "Iteration 21, loss = 0.16814344\n",
            "Iteration 22, loss = 0.16605019\n",
            "Iteration 23, loss = 0.16340563\n",
            "Iteration 24, loss = 0.15967678\n",
            "Iteration 25, loss = 0.16100704\n",
            "Iteration 26, loss = 0.15850639\n",
            "Iteration 27, loss = 0.16261859\n",
            "Iteration 28, loss = 0.15731580\n",
            "Iteration 29, loss = 0.15392136\n",
            "Iteration 30, loss = 0.15021089\n",
            "Iteration 31, loss = 0.14984303\n",
            "Iteration 32, loss = 0.15099348\n",
            "Iteration 33, loss = 0.14651927\n",
            "Iteration 34, loss = 0.14626206\n",
            "Iteration 35, loss = 0.14944927\n",
            "Iteration 36, loss = 0.14785073\n",
            "Iteration 37, loss = 0.14448256\n",
            "Iteration 38, loss = 0.14249993\n",
            "Iteration 39, loss = 0.14042678\n",
            "Iteration 40, loss = 0.14135530\n",
            "Iteration 41, loss = 0.13872699\n",
            "Iteration 42, loss = 0.13694941\n",
            "Iteration 43, loss = 0.13705024\n",
            "Iteration 44, loss = 0.13704693\n",
            "Iteration 45, loss = 0.13481393\n",
            "Iteration 46, loss = 0.14125848\n",
            "Iteration 47, loss = 0.13242934\n",
            "Iteration 48, loss = 0.13090164\n",
            "Iteration 49, loss = 0.12895370\n",
            "Iteration 50, loss = 0.13084886\n",
            "Iteration 51, loss = 0.13081353\n",
            "Iteration 52, loss = 0.12859488\n",
            "Iteration 53, loss = 0.13195073\n",
            "Iteration 54, loss = 0.12771857\n",
            "Iteration 55, loss = 0.12938657\n",
            "Iteration 56, loss = 0.12742702\n",
            "Iteration 57, loss = 0.12880341\n",
            "Iteration 58, loss = 0.12307054\n",
            "Iteration 59, loss = 0.12461769\n",
            "Iteration 60, loss = 0.12285898\n",
            "Iteration 61, loss = 0.12238450\n",
            "Iteration 62, loss = 0.12208064\n",
            "Iteration 63, loss = 0.12158501\n",
            "Iteration 64, loss = 0.12130337\n",
            "Iteration 65, loss = 0.12093176\n",
            "Iteration 66, loss = 0.11972458\n",
            "Iteration 67, loss = 0.11974113\n",
            "Iteration 68, loss = 0.11930556\n",
            "Iteration 69, loss = 0.12007683\n",
            "Iteration 70, loss = 0.11722478\n",
            "Iteration 71, loss = 0.11902100\n",
            "Iteration 72, loss = 0.11502276\n",
            "Iteration 73, loss = 0.11352749\n",
            "Iteration 74, loss = 0.11571672\n",
            "Iteration 75, loss = 0.11583793\n",
            "Iteration 76, loss = 0.11261002\n",
            "Iteration 77, loss = 0.11615227\n",
            "Iteration 78, loss = 0.11626344\n",
            "Iteration 79, loss = 0.11490947\n",
            "Iteration 80, loss = 0.11398291\n",
            "Iteration 81, loss = 0.11201602\n",
            "Iteration 82, loss = 0.10986320\n",
            "Iteration 83, loss = 0.11239309\n",
            "Iteration 84, loss = 0.10788455\n",
            "Iteration 85, loss = 0.11187401\n",
            "Iteration 86, loss = 0.10924326\n",
            "Iteration 87, loss = 0.11037879\n",
            "Iteration 88, loss = 0.10866711\n",
            "Iteration 89, loss = 0.10733264\n",
            "Iteration 90, loss = 0.11005975\n",
            "Iteration 91, loss = 0.10912118\n",
            "Iteration 92, loss = 0.10668518\n",
            "Iteration 93, loss = 0.10610152\n",
            "Iteration 94, loss = 0.10362954\n",
            "Iteration 95, loss = 0.10545805\n",
            "Iteration 96, loss = 0.10710804\n",
            "Iteration 97, loss = 0.10796063\n",
            "Iteration 98, loss = 0.10499508\n",
            "Iteration 99, loss = 0.10699537\n",
            "Iteration 100, loss = 0.10064709\n",
            "Iteration 101, loss = 0.10508950\n",
            "Iteration 102, loss = 0.10643055\n",
            "Iteration 103, loss = 0.10612271\n",
            "Iteration 104, loss = 0.10849620\n",
            "Iteration 105, loss = 0.10335565\n",
            "Iteration 106, loss = 0.10087533\n",
            "Iteration 107, loss = 0.10639803\n",
            "Iteration 108, loss = 0.11054957\n",
            "Iteration 109, loss = 0.10330665\n",
            "Iteration 110, loss = 0.10489228\n",
            "Iteration 111, loss = 0.10083887\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Time taken to train model: 174.84 seconds\n",
            "Average cross-validation accuracy: 0.94\n",
            "Testing accuracy: 0.95\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP with pca"
      ],
      "metadata": {
        "id": "chAUNQDnIL5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca, X_test_pca, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=30)"
      ],
      "metadata": {
        "id": "UPft40c0I-nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "clf = MLPClassifier(hidden_layer_sizes=(50, 50, 50, 50), max_iter=20, alpha=0.0001,\n",
        "                    verbose=10, random_state=5, tol=0.000000001,\n",
        "                    activation='relu', solver='adam', batch_size=64,\n",
        "                    # Set logistic activation for the output layer\n",
        "                    )\n",
        "\n",
        "# Use GridSearchCV with 3-fold cross-validation to find the optimal hyperparameters\n",
        "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=3)\n",
        "grid_search.fit(X_train_pca, y_train)\n",
        "best_clf = grid_search.best_estimator_\n",
        "\n",
        "# Use cross-validation with 5 folds to evaluate the trained model\n",
        "scores = cross_val_score(best_clf, X_train_pca, y_train, cv=5)\n",
        "\n",
        "# Evaluate the trained model on the test set\n",
        "y_pred = best_clf.predict(X_test_pca)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vAQMtrV6Gda-",
        "outputId": "58d97059-00dc-4d94-d87a-88329c6b7a79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31913954\n",
            "Iteration 2, loss = 0.24917893\n",
            "Iteration 3, loss = 0.23454951\n",
            "Iteration 4, loss = 0.22478006\n",
            "Iteration 5, loss = 0.21786061\n",
            "Iteration 6, loss = 0.21214965\n",
            "Iteration 7, loss = 0.21169689\n",
            "Iteration 8, loss = 0.20251063\n",
            "Iteration 9, loss = 0.19886334\n",
            "Iteration 10, loss = 0.19708654\n",
            "Iteration 11, loss = 0.19137171\n",
            "Iteration 12, loss = 0.18787198\n",
            "Iteration 13, loss = 0.18584792\n",
            "Iteration 14, loss = 0.18329841\n",
            "Iteration 15, loss = 0.17948354\n",
            "Iteration 16, loss = 0.17641534\n",
            "Iteration 17, loss = 0.17246807\n",
            "Iteration 18, loss = 0.17433654\n",
            "Iteration 19, loss = 0.16733546\n",
            "Iteration 20, loss = 0.16530414\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31864386\n",
            "Iteration 2, loss = 0.24992970\n",
            "Iteration 3, loss = 0.23259075\n",
            "Iteration 4, loss = 0.22541621\n",
            "Iteration 5, loss = 0.21899220\n",
            "Iteration 6, loss = 0.21364271\n",
            "Iteration 7, loss = 0.21092245\n",
            "Iteration 8, loss = 0.20559803\n",
            "Iteration 9, loss = 0.20302833\n",
            "Iteration 10, loss = 0.19843973\n",
            "Iteration 11, loss = 0.19190629\n",
            "Iteration 12, loss = 0.19301795\n",
            "Iteration 13, loss = 0.18677544\n",
            "Iteration 14, loss = 0.18391379\n",
            "Iteration 15, loss = 0.18482877\n",
            "Iteration 16, loss = 0.18066266\n",
            "Iteration 17, loss = 0.17867529\n",
            "Iteration 18, loss = 0.17178342\n",
            "Iteration 19, loss = 0.16910971\n",
            "Iteration 20, loss = 0.16934861\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31913016\n",
            "Iteration 2, loss = 0.24998555\n",
            "Iteration 3, loss = 0.23052037\n",
            "Iteration 4, loss = 0.22332313\n",
            "Iteration 5, loss = 0.21773875\n",
            "Iteration 6, loss = 0.21127779\n",
            "Iteration 7, loss = 0.20878148\n",
            "Iteration 8, loss = 0.20228614\n",
            "Iteration 9, loss = 0.19918886\n",
            "Iteration 10, loss = 0.19307298\n",
            "Iteration 11, loss = 0.18845221\n",
            "Iteration 12, loss = 0.18657235\n",
            "Iteration 13, loss = 0.18819953\n",
            "Iteration 14, loss = 0.18041276\n",
            "Iteration 15, loss = 0.17947999\n",
            "Iteration 16, loss = 0.17629629\n",
            "Iteration 17, loss = 0.16997777\n",
            "Iteration 18, loss = 0.16895922\n",
            "Iteration 19, loss = 0.16663064\n",
            "Iteration 20, loss = 0.16507819\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.28599752\n",
            "Iteration 2, loss = 0.24383371\n",
            "Iteration 3, loss = 0.23458845\n",
            "Iteration 4, loss = 0.23199733\n",
            "Iteration 5, loss = 0.22511441\n",
            "Iteration 6, loss = 0.21938460\n",
            "Iteration 7, loss = 0.22456756\n",
            "Iteration 8, loss = 0.21721394\n",
            "Iteration 9, loss = 0.21241837\n",
            "Iteration 10, loss = 0.20783343\n",
            "Iteration 11, loss = 0.20315551\n",
            "Iteration 12, loss = 0.20000406\n",
            "Iteration 13, loss = 0.20077325\n",
            "Iteration 14, loss = 0.19540601\n",
            "Iteration 15, loss = 0.19366102\n",
            "Iteration 16, loss = 0.18665249\n",
            "Iteration 17, loss = 0.18804961\n",
            "Iteration 18, loss = 0.18429461\n",
            "Iteration 19, loss = 0.17891601\n",
            "Iteration 20, loss = 0.18174052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.29269731\n",
            "Iteration 2, loss = 0.23939370\n",
            "Iteration 3, loss = 0.23824443\n",
            "Iteration 4, loss = 0.23287711\n",
            "Iteration 5, loss = 0.23155934\n",
            "Iteration 6, loss = 0.22251650\n",
            "Iteration 7, loss = 0.21858058\n",
            "Iteration 8, loss = 0.21502759\n",
            "Iteration 9, loss = 0.22198159\n",
            "Iteration 10, loss = 0.21163829\n",
            "Iteration 11, loss = 0.20499581\n",
            "Iteration 12, loss = 0.20951443\n",
            "Iteration 13, loss = 0.20127136\n",
            "Iteration 14, loss = 0.19936484\n",
            "Iteration 15, loss = 0.19850301\n",
            "Iteration 16, loss = 0.19397274\n",
            "Iteration 17, loss = 0.18849428\n",
            "Iteration 18, loss = 0.19045300\n",
            "Iteration 19, loss = 0.18704501\n",
            "Iteration 20, loss = 0.18684157\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.28729193\n",
            "Iteration 2, loss = 0.24374669\n",
            "Iteration 3, loss = 0.22776203\n",
            "Iteration 4, loss = 0.22549575\n",
            "Iteration 5, loss = 0.22164580\n",
            "Iteration 6, loss = 0.21654776\n",
            "Iteration 7, loss = 0.20951162\n",
            "Iteration 8, loss = 0.21365650\n",
            "Iteration 9, loss = 0.20912322\n",
            "Iteration 10, loss = 0.20067303\n",
            "Iteration 11, loss = 0.20113461\n",
            "Iteration 12, loss = 0.19600083\n",
            "Iteration 13, loss = 0.20174325\n",
            "Iteration 14, loss = 0.20228236\n",
            "Iteration 15, loss = 0.21441251\n",
            "Iteration 16, loss = 0.20284158\n",
            "Iteration 17, loss = 0.19407193\n",
            "Iteration 18, loss = 0.18908267\n",
            "Iteration 19, loss = 0.18305167\n",
            "Iteration 20, loss = 0.18256161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.40357121\n",
            "Iteration 2, loss = 0.26061648\n",
            "Iteration 3, loss = 0.25289995\n",
            "Iteration 4, loss = 0.36286153\n",
            "Iteration 5, loss = 0.34486994\n",
            "Iteration 6, loss = 0.32011537\n",
            "Iteration 7, loss = 0.33605219\n",
            "Iteration 8, loss = 0.32277305\n",
            "Iteration 9, loss = 0.29054770\n",
            "Iteration 10, loss = 0.27005832\n",
            "Iteration 11, loss = 0.30126759\n",
            "Iteration 12, loss = 0.26393543\n",
            "Iteration 13, loss = 0.26376698\n",
            "Iteration 14, loss = 0.26594452\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.39100688\n",
            "Iteration 2, loss = 0.35321494\n",
            "Iteration 3, loss = 0.34616225\n",
            "Iteration 4, loss = 0.36315051\n",
            "Iteration 5, loss = 0.35644259\n",
            "Iteration 6, loss = 0.36381144\n",
            "Iteration 7, loss = 0.37513404\n",
            "Iteration 8, loss = 0.37209841\n",
            "Iteration 9, loss = 0.35262329\n",
            "Iteration 10, loss = 0.34717676\n",
            "Iteration 11, loss = 0.33690714\n",
            "Iteration 12, loss = 0.33751322\n",
            "Iteration 13, loss = 0.33786566\n",
            "Iteration 14, loss = 0.35008250\n",
            "Iteration 15, loss = 0.36421837\n",
            "Iteration 16, loss = 0.36358334\n",
            "Iteration 17, loss = 0.36431911\n",
            "Iteration 18, loss = 0.36377704\n",
            "Iteration 19, loss = 0.36432864\n",
            "Iteration 20, loss = 0.36528968\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.34125687\n",
            "Iteration 2, loss = 0.40147802\n",
            "Iteration 3, loss = 0.38158777\n",
            "Iteration 4, loss = 0.38163470\n",
            "Iteration 5, loss = 0.38196617\n",
            "Iteration 6, loss = 0.38159858\n",
            "Iteration 7, loss = 0.38210711\n",
            "Iteration 8, loss = 0.38128102\n",
            "Iteration 9, loss = 0.38067922\n",
            "Iteration 10, loss = 0.38067514\n",
            "Iteration 11, loss = 0.38051906\n",
            "Iteration 12, loss = 0.38107484\n",
            "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n",
            "Iteration 1, loss = 0.29378767\n",
            "Iteration 2, loss = 0.23786850\n",
            "Iteration 3, loss = 0.22287776\n",
            "Iteration 4, loss = 0.21734769\n",
            "Iteration 5, loss = 0.21076838\n",
            "Iteration 6, loss = 0.20386627\n",
            "Iteration 7, loss = 0.20083564\n",
            "Iteration 8, loss = 0.19531344\n",
            "Iteration 9, loss = 0.19238007\n",
            "Iteration 10, loss = 0.18659015\n",
            "Iteration 11, loss = 0.18368471\n",
            "Iteration 12, loss = 0.17862524\n",
            "Iteration 13, loss = 0.17454521\n",
            "Iteration 14, loss = 0.17133331\n",
            "Iteration 15, loss = 0.16919724\n",
            "Iteration 16, loss = 0.16638101\n",
            "Iteration 17, loss = 0.16292259\n",
            "Iteration 18, loss = 0.16046437\n",
            "Iteration 19, loss = 0.15932335\n",
            "Iteration 20, loss = 0.15930443\n",
            "Iteration 1, loss = 0.30793564\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 2, loss = 0.23967493\n",
            "Iteration 3, loss = 0.22792836\n",
            "Iteration 4, loss = 0.21738608\n",
            "Iteration 5, loss = 0.21441542\n",
            "Iteration 6, loss = 0.20767200\n",
            "Iteration 7, loss = 0.20431215\n",
            "Iteration 8, loss = 0.20025742\n",
            "Iteration 9, loss = 0.19951869\n",
            "Iteration 10, loss = 0.19137025\n",
            "Iteration 11, loss = 0.18802461\n",
            "Iteration 12, loss = 0.18494114\n",
            "Iteration 13, loss = 0.18193464\n",
            "Iteration 14, loss = 0.17855299\n",
            "Iteration 15, loss = 0.17548650\n",
            "Iteration 16, loss = 0.17081104\n",
            "Iteration 17, loss = 0.16811068\n",
            "Iteration 18, loss = 0.16676409\n",
            "Iteration 19, loss = 0.16266374\n",
            "Iteration 20, loss = 0.16178370\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.30415209\n",
            "Iteration 2, loss = 0.24306255\n",
            "Iteration 3, loss = 0.23248200\n",
            "Iteration 4, loss = 0.22458746\n",
            "Iteration 5, loss = 0.21728284\n",
            "Iteration 6, loss = 0.21150708\n",
            "Iteration 7, loss = 0.20544396\n",
            "Iteration 8, loss = 0.20240432\n",
            "Iteration 9, loss = 0.19781991\n",
            "Iteration 10, loss = 0.19080917\n",
            "Iteration 11, loss = 0.18858427\n",
            "Iteration 12, loss = 0.18313203\n",
            "Iteration 13, loss = 0.18233101\n",
            "Iteration 14, loss = 0.17738133\n",
            "Iteration 15, loss = 0.17613033\n",
            "Iteration 16, loss = 0.17291589\n",
            "Iteration 17, loss = 0.16743505\n",
            "Iteration 18, loss = 0.16703042\n",
            "Iteration 19, loss = 0.16463381\n",
            "Iteration 20, loss = 0.16305630\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.31123760\n",
            "Iteration 2, loss = 0.24376942\n",
            "Iteration 3, loss = 0.22828226\n",
            "Iteration 4, loss = 0.22506647\n",
            "Iteration 5, loss = 0.21687141\n",
            "Iteration 6, loss = 0.21197248\n",
            "Iteration 7, loss = 0.20625686\n",
            "Iteration 8, loss = 0.20482251\n",
            "Iteration 9, loss = 0.19823146\n",
            "Iteration 10, loss = 0.19455476\n",
            "Iteration 11, loss = 0.19014009\n",
            "Iteration 12, loss = 0.18698514\n",
            "Iteration 13, loss = 0.18647328\n",
            "Iteration 14, loss = 0.18107716\n",
            "Iteration 15, loss = 0.18174222\n",
            "Iteration 16, loss = 0.17571140\n",
            "Iteration 17, loss = 0.17556345\n",
            "Iteration 18, loss = 0.17043549\n",
            "Iteration 19, loss = 0.17016196\n",
            "Iteration 20, loss = 0.16614031\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.30202981\n",
            "Iteration 2, loss = 0.23835834\n",
            "Iteration 3, loss = 0.22520199\n",
            "Iteration 4, loss = 0.21786149\n",
            "Iteration 5, loss = 0.21128564\n",
            "Iteration 6, loss = 0.20449022\n",
            "Iteration 7, loss = 0.20078555\n",
            "Iteration 8, loss = 0.19862230\n",
            "Iteration 9, loss = 0.19299775\n",
            "Iteration 10, loss = 0.18783653\n",
            "Iteration 11, loss = 0.18623817\n",
            "Iteration 12, loss = 0.18107506\n",
            "Iteration 13, loss = 0.17862592\n",
            "Iteration 14, loss = 0.17576256\n",
            "Iteration 15, loss = 0.17121530\n",
            "Iteration 16, loss = 0.16688363\n",
            "Iteration 17, loss = 0.16764082\n",
            "Iteration 18, loss = 0.16622430\n",
            "Iteration 19, loss = 0.16377359\n",
            "Iteration 20, loss = 0.15992212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.30847262\n",
            "Iteration 2, loss = 0.24395910\n",
            "Iteration 3, loss = 0.22886506\n",
            "Iteration 4, loss = 0.21874656\n",
            "Iteration 5, loss = 0.21270937\n",
            "Iteration 6, loss = 0.20899151\n",
            "Iteration 7, loss = 0.20175472\n",
            "Iteration 8, loss = 0.19864703\n",
            "Iteration 9, loss = 0.19453027\n",
            "Iteration 10, loss = 0.18977418\n",
            "Iteration 11, loss = 0.18392096\n",
            "Iteration 12, loss = 0.18092278\n",
            "Iteration 13, loss = 0.17896836\n",
            "Iteration 14, loss = 0.17652896\n",
            "Iteration 15, loss = 0.17245583\n",
            "Iteration 16, loss = 0.17097204\n",
            "Iteration 17, loss = 0.16849811\n",
            "Iteration 18, loss = 0.16461171\n",
            "Iteration 19, loss = 0.16445414\n",
            "Iteration 20, loss = 0.15997690\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (20) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "accuracy = best_clf.score(X_test_pca, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bAQqWmU-H8i5",
        "outputId": "3919aa42-ed0e-4a9a-9a69-4fe6b599ed8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93910379 0.94216775 0.93948679 0.93680582 0.94291188]\n",
            "Mean cross-validation score: 0.9400952058121328\n",
            "Test set accuracy: 0.935049\n",
            "Sensitivity:  [0.98322851 0.5920398 ]\n",
            "Specificity:  [-0.07300613 -0.86319018]\n",
            "Best hyperparameters:  {'learning_rate_init': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create an SVM classifier with a linear kernel\n",
        "svm = SVC(kernel='linear')\n",
        "svm.fit(X_train_pca, y_train)\n",
        "# Perform 10-fold cross-validation on the training data and calculate the mean accuracy score\n",
        "scores = cross_val_score(svm, X_train, y_train, cv=10)\n",
        "mean_accuracy = scores.mean()\n",
        "\n",
        "print(\"Mean accuracy:\", mean_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoBiS53IrUU-",
        "outputId": "b1581747-9161-451a-e5d2-0039202d9e21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean accuracy: 0.9270723392770179\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "y_pred6 = svm.predict(X_test_pca)"
      ],
      "metadata": {
        "id": "opgt1t9QO1NX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred6)\n",
        "accuracy = best_clf.score(X_test_pca, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)\n",
        "print(\"Best hyperparameters: \", grid_search.best_params_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_FqfQW0BKU72",
        "outputId": "a0392e6d-2d26-4d1f-d3ac-f5e365b407ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93032159 0.9287902  0.92343032 0.92343032 0.9302682  0.92183908\n",
            " 0.92873563 0.92260536 0.92796935 0.93333333]\n",
            "Mean cross-validation score: 0.9270723392770179\n",
            "Test set accuracy: 0.810662\n",
            "Sensitivity:  [1. 0.]\n",
            "Specificity:  [-0.         -0.87361963]\n",
            "Best hyperparameters:  {'learning_rate_init': 0.001}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import cross_val_score, KFold\n",
        "\n",
        "# Load your training data into X_train and y_train arrays\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a KNN classifier object\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "\n",
        "# Define the number of folds for cross-validation\n",
        "num_folds = 5\n",
        "\n",
        "# Define the k-fold cross-validation technique\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Perform cross-validation on the training data\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=kfold)\n",
        "# Train the model on the training set\n",
        "knn.fit(X_train_pca, y_train)\n",
        "\n",
        "# Print the cross-validation scores\n",
        "print(\"Cross-validation scores: {}\".format(scores))\n",
        "print(\"Mean accuracy: {:.2f}\".format(scores.mean()))\n",
        "print(\"Standard deviation: {:.2f}\".format(scores.std()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uU3BhI0Bx42o",
        "outputId": "8eeaff88-56cb-4558-8f4b-57ef53657545"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93489085 0.92837993 0.93527384 0.94101877 0.93639847]\n",
            "Mean accuracy: 0.94\n",
            "Standard deviation: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn.fit(X_train_pca, y_train)\n",
        "# Predict the labels of the test set\n",
        "y_pred4 = knn.predict(X_test_pca)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = knn.score(X_test_pca, y_pred4)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23aIAmB0Kfg9",
        "outputId": "c9776c41-8c93-4faf-c1eb-a495fec50d7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred4)\n",
        "accuracy = knn.score(X_test_pca, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCMtV7VrK2fr",
        "outputId": "285df0b4-2968-4c8b-f3da-2c22fb02e721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93032159 0.9287902  0.92343032 0.92343032 0.9302682  0.92183908\n",
            " 0.92873563 0.92260536 0.92796935 0.93333333]\n",
            "Mean cross-validation score: 0.9270723392770179\n",
            "Test set accuracy: 0.872243\n",
            "Sensitivity:  [0.99929775 0.00240385]\n",
            "Specificity:  [-3.06748466e-04 -8.73006135e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "# Calculate the confusion matrix\n",
        "tn, fp, fn, tp = confusion_matrix(y_test, y_pred4).ravel()\n",
        "\n",
        "# Calculate the specificity score\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)"
      ],
      "metadata": {
        "id": "q_L-hNs5YBdi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1118b414-4532-4441-df01-451631164b22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Specificity: 0.9992977528089888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train a Gaussian Naive Bayes classifier on the training set\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train_pca, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "y_pred = clf.predict(X_test_pca)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI3VpJnASMk3",
        "outputId": "03ffab0a-be89-4bdf-f81a-0e0dc9aeaf32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.788296568627451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "accuracy = knn.score(X_test_pca, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4nzO_N3Tfps",
        "outputId": "66d0f7a1-3f90-4b3d-b544-0c53af65631e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93032159 0.9287902  0.92343032 0.92343032 0.9302682  0.92183908\n",
            " 0.92873563 0.92260536 0.92796935 0.93333333]\n",
            "Mean cross-validation score: 0.9270723392770179\n",
            "Test set accuracy: 0.872243\n",
            "Sensitivity:  [0.93328652 0.0625    ]\n",
            "Specificity:  [-0.00797546 -0.81533742]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train a Gaussian Naive Bayes classifier on the training set\n",
        "clf = GaussianNB()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the testing set\n",
        "y_pred = clf.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print('Accuracy:', acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GSIr2qsWSWVo",
        "outputId": "cc7666eb-a08d-436e-8d0c-5e708a0d6311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8762254901960784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy, sensitivity, and specificity\n",
        "conf_mat = confusion_matrix(y_test, y_pred)\n",
        "accuracy = knn.score(X_test_pca, y_test)\n",
        "sensitivity = conf_mat.diagonal()/conf_mat.sum(axis=1)\n",
        "specificity = (np.trace(conf_mat)-conf_mat.diagonal())/((conf_mat.shape[0]*conf_mat.shape[1])-np.sum(conf_mat))\n",
        "\n",
        "# Print results\n",
        "print(\"Cross-validation scores:\", scores)\n",
        "print(\"Mean cross-validation score:\", np.mean(scores))\n",
        "print(\"Test set accuracy: %f\" % accuracy)\n",
        "print(\"Sensitivity: \", sensitivity)\n",
        "print(\"Specificity: \", specificity)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cucPtn2BT9Ah",
        "outputId": "d8fea0fe-563e-45d5-8ec3-b3c0896d959a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: [0.93032159 0.9287902  0.92343032 0.92343032 0.9302682  0.92183908\n",
            " 0.92873563 0.92260536 0.92796935 0.93333333]\n",
            "Mean cross-validation score: 0.9270723392770179\n",
            "Test set accuracy: 0.872243\n",
            "Sensitivity:  [0.96488764 0.26923077]\n",
            "Specificity:  [-0.03435583 -0.84294479]\n"
          ]
        }
      ]
    }
  ]
}